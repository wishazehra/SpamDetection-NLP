{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bunch1', 'bunch2', 'bunch3']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=['observation'])\n",
    "\n",
    "path = 'C:\\\\Users\\\\Admin\\\\Desktop\\\\EnronMeetings-XML\\\\train'\n",
    "dir_list = os.listdir('C:\\\\Users\\\\Admin\\\\Desktop\\\\EnronMeetings-XML\\\\train')\n",
    "dir_list.sort()\n",
    "print (dir_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting content of email from all train text files\n",
    "for i in dir_list:\n",
    "    file_list = os.listdir('C:\\\\Users\\\\Admin\\\\Desktop\\\\EnronMeetings-XML\\\\train\\\\' + i)\n",
    "    for f in file_list:\n",
    "        path = 'C:\\\\Users\\\\Admin\\\\Desktop\\\\EnronMeetings-XML\\\\train\\\\' + i + '/' + f\n",
    "        with open(path) as fi:\n",
    "            line = ''\n",
    "            found = False\n",
    "            for word in fi.read().split():\n",
    "                if word in ['7Bit', '7bit']:\n",
    "                    found = True\n",
    "                if found:\n",
    "                    line = line + ' ' + word\n",
    "\n",
    "            current_df = pd.DataFrame({'observation': [line]})\n",
    "            df = df.append(current_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7bit Bcc: shona.wilson@enron.com This meeting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7bit Review available services with OATI for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7bit Concerning traders news information, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7bit As per our conversation, we will be meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7bit Traders News Meeting &lt;true_name&gt; Chuck &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>7bit Bcc: jay.webb@enron.com, legal &lt;.taylor@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>7bit Thought you may be interested in this as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>7bit Bcc: debra.bailey@enron.com, rika.imai@e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>7bit Bcc: paul.racicot@enron.com, sheila.twee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>7bit Read Shopgirl by &lt;true_name&gt; Steve Marti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>729 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           observation\n",
       "0     7bit Bcc: shona.wilson@enron.com This meeting...\n",
       "1     7bit Review available services with OATI for ...\n",
       "2     7bit Concerning traders news information, and...\n",
       "3     7bit As per our conversation, we will be meet...\n",
       "4     7bit Traders News Meeting <true_name> Chuck <...\n",
       "..                                                 ...\n",
       "724   7bit Bcc: jay.webb@enron.com, legal <.taylor@...\n",
       "725   7bit Thought you may be interested in this as...\n",
       "726   7bit Bcc: debra.bailey@enron.com, rika.imai@e...\n",
       "727   7bit Bcc: paul.racicot@enron.com, sheila.twee...\n",
       "728   7bit Read Shopgirl by <true_name> Steve Marti...\n",
       "\n",
       "[729 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 729/729 [00:00<00:00, 748.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "#classifying as spam or ham uisng a list of spam words\n",
    "df2 = pd.DataFrame(columns=['text', 'spam'])\n",
    "for i in tqdm(range(len(df))):\n",
    "    spam = '0'\n",
    "    for word in df.observation[i].split():\n",
    "        text = df.observation[i]\n",
    "        if word in ['now', 'urgent', 'do','ready', 'news', 'please', 'interested', 'call', 'right', 'sale', 'spent', 'vacation']:\n",
    "            spam = '1'\n",
    "\n",
    "    current_df2 = pd.DataFrame({'text': [text], 'spam': [spam]})\n",
    "    df2 = df2.append(current_df2, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7bit Bcc: shona.wilson@enron.com This meeting...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7bit Review available services with OATI for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7bit Concerning traders news information, and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7bit As per our conversation, we will be meet...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7bit Traders News Meeting &lt;true_name&gt; Chuck &lt;...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>7bit Bcc: jay.webb@enron.com, legal &lt;.taylor@...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>7bit Thought you may be interested in this as...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>7bit Bcc: debra.bailey@enron.com, rika.imai@e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>7bit Bcc: paul.racicot@enron.com, sheila.twee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>7bit Read Shopgirl by &lt;true_name&gt; Steve Marti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>729 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text spam\n",
       "0     7bit Bcc: shona.wilson@enron.com This meeting...    0\n",
       "1     7bit Review available services with OATI for ...    0\n",
       "2     7bit Concerning traders news information, and...    1\n",
       "3     7bit As per our conversation, we will be meet...    0\n",
       "4     7bit Traders News Meeting <true_name> Chuck <...    0\n",
       "..                                                 ...  ...\n",
       "724   7bit Bcc: jay.webb@enron.com, legal <.taylor@...    1\n",
       "725   7bit Thought you may be interested in this as...    1\n",
       "726   7bit Bcc: debra.bailey@enron.com, rika.imai@e...    0\n",
       "727   7bit Bcc: paul.racicot@enron.com, sheila.twee...    0\n",
       "728   7bit Read Shopgirl by <true_name> Steve Marti...    0\n",
       "\n",
       "[729 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [7bit, Bcc, shonawilsonenroncom, meeting, resc...\n",
       "1    [7bit, Review, available, services, OATI, East...\n",
       "2    [7bit, Concerning, traders, news, information,...\n",
       "3    [7bit, per, conversation, meeting, truename, K...\n",
       "4    [7bit, Traders, News, Meeting, truename, Chuck...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "def process_text(text):\n",
    "    # 1 Remove Punctuationa\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "\n",
    "    # 2 Remove Stop Words\n",
    "    clean_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "\n",
    "    # 3 Return a list of clean words\n",
    "    return clean_words\n",
    "\n",
    "\n",
    "df2['text'].head().apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "messages_bow = CountVectorizer(analyzer=process_text).fit_transform(df2['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into 80% training & 20% testing data sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages_bow, df2['spam'], test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(729, 4514)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the shape of messages_bow\n",
    "messages_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '0' '1' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '1' '0' '0' '1' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '1' '0' '0'\n",
      " '0' '1' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '1' '1' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '1' '1' '0' '1' '0' '0' '0' '0' '0' '1' '0'\n",
      " '0' '0' '0' '0' '1' '1' '0' '0' '0' '1' '1' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '1'\n",
      " '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0'\n",
      " '0' '1' '0' '0' '0' '0' '1' '0' '0' '0' '0' '1' '1' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0'\n",
      " '0' '1' '0' '0' '1' '0' '0' '0' '1' '0' '0' '1' '0' '0' '1' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '1' '0' '0'\n",
      " '0' '0' '1' '0' '1' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '1' '0' '0' '0' '0' '1' '1' '0' '0' '0' '1' '0' '0' '1' '0' '0' '0' '0'\n",
      " '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '1' '0' '0' '0' '0' '0'\n",
      " '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '1' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '1' '1' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0'\n",
      " '0' '0' '1' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '1' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '1' '1' '0' '1' '0' '0'\n",
      " '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0'\n",
      " '0' '1' '0' '0' '1' '0' '0' '0' '1' '0' '1' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '1' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0']\n",
      "['0' '0' '1' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '1' '1' '0' '1' '0' '0' '1' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '1' '1' '0' '0'\n",
      " '0' '1' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '1' '1' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '1' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '1' '1' '0' '1' '0' '0' '0' '0' '0' '1' '0'\n",
      " '0' '0' '0' '0' '1' '0' '0' '0' '0' '1' '1' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0'\n",
      " '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0'\n",
      " '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '1' '1' '0' '0' '0' '0' '0' '0'\n",
      " '0' '1' '0' '0' '0' '0' '1' '0' '0' '0' '0' '1' '1' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0'\n",
      " '0' '1' '0' '0' '1' '0' '0' '0' '1' '0' '0' '1' '0' '0' '1' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '1' '0' '0'\n",
      " '0' '0' '1' '0' '1' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '1' '0' '0' '0' '0' '1' '1' '0' '0' '0' '1' '0' '0' '1' '0' '0' '0' '0'\n",
      " '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '1' '0' '0' '0' '0' '0'\n",
      " '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '1' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '1' '1' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0'\n",
      " '0' '0' '1' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0'\n",
      " '0' '0' '1' '0' '1' '0' '0' '0' '0' '0' '0' '0' '1' '1' '0' '1' '0' '0'\n",
      " '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0'\n",
      " '0' '1' '0' '0' '1' '0' '0' '0' '1' '0' '1' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '1' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0']\n"
     ]
    }
   ],
   "source": [
    "#Print the predictions\n",
    "print(classifier.predict(X_train))\n",
    "#Print the actual values\n",
    "print(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       499\n",
      "           1       0.96      0.90      0.93        84\n",
      "\n",
      "    accuracy                           0.98       583\n",
      "   macro avg       0.97      0.95      0.96       583\n",
      "weighted avg       0.98      0.98      0.98       583\n",
      "\n",
      "Confusion Matrix: \n",
      " [[496   3]\n",
      " [  8  76]]\n",
      "\n",
      "Accuracy:  0.9811320754716981\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on the training data set\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "pred = classifier.predict(X_train)\n",
    "print(classification_report(y_train ,pred ))\n",
    "print('Confusion Matrix: \\n',confusion_matrix(y_train,pred))\n",
    "print()\n",
    "print('Accuracy: ', accuracy_score(y_train,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value:  ['0' '0' '0' '0' '1' '0' '0' '1' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '1' '0' '0' '1' '0'\n",
      " '1' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '1' '1' '1' '0' '0' '0'\n",
      " '0' '0' '0' '1' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '1' '0' '1' '0'\n",
      " '0' '0' '0' '0' '0' '0' '1' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '1' '0' '1' '0' '1' '0'\n",
      " '0' '0' '0' '0' '0' '1' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '1'\n",
      " '0' '0' '0' '1' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0']\n",
      "Actual value:  ['0' '0' '0' '0' '1' '0' '1' '1' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '1' '0'\n",
      " '0' '0' '0' '0' '0' '0' '1' '0' '1' '0' '0' '0' '1' '1' '0' '0' '0' '0'\n",
      " '1' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '1' '0' '1' '0'\n",
      " '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '1' '0' '0' '1'\n",
      " '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '1' '0' '1' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1'\n",
      " '0' '0']\n"
     ]
    }
   ],
   "source": [
    "#Print the predictions\n",
    "print('Predicted value: ',classifier.predict(X_test))\n",
    "#Print Actual Label\n",
    "print('Actual value: ',y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93       122\n",
      "           1       0.62      0.67      0.64        24\n",
      "\n",
      "    accuracy                           0.88       146\n",
      "   macro avg       0.77      0.79      0.78       146\n",
      "weighted avg       0.88      0.88      0.88       146\n",
      "\n",
      "Confusion Matrix: \n",
      " [[112  10]\n",
      " [  8  16]]\n",
      "\n",
      "Accuracy:  0.8767123287671232\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on the test data set\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test ,pred ))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test,pred))\n",
    "print()\n",
    "print('Accuracy: ', accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
